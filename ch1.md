ch1

```

```
1. 机器学习不是简单的输入得到输出，附加了对数据的自动处理得到一定的输出结果，基于统计，相关而非因果是根基
2. 大量真实数据集的网站：archive.ics.uci.edu/ml/datasets.html
3. 统计学中结构风险最小化SRM就是研究欠拟合和过拟合，与传统的经验风险最小化ERM相比，注重于对风险上界的最小化
4. 泛化能力足够好，对模型做出一定的限制或惩罚，从而使模型趋于精简，这与所谓的奥卡姆剃刀原理不谋而合，如无必要，勿增实体、切勿浪费较多的东西去做，用较少的东西同样可以做好的事情
5. 交叉验证有以下三种，1）S折交叉验证，应用最多的一种方法，将数据分为S份，一共做S次实验。在I次实验中，使用D-Di作为训练集，Di作为测试集对模型进行训练和评测，最终选择平均测试误差最小的模型；2）留一交叉验证，这是S折交叉验证的特殊情况，此时S=N;3)简易交叉验证：这种实现起来最简单，也是本书所采用的方法。它简单地将数据进行随机分组，最后达到训练集约占原数据70%的程度（比例可以视情况而定），选择模型时使用测试误差作为标准。
6. 数据标准化，https://baike.baidu.com/item/数据标准化/4132085?fr=aladdin
7. 最大最小标准化，Z-score标准化
8. https://github.com/carefree0910/MachineLearning/tree/master/_Data
9. 线性回归进行多项式拟合，f(x|n;p)多项式的具体形式
10. 损失函数L(x|p;n)，常见的平方损失函数，也就是所谓的欧式距离（向量的二范数），模型训练则是为了损失函数最小，n为次数，p为系数
11. 求损失函数的最小系数polyfit(x,y,deg),polyval(p,x)根据多项式系数p和x的值，返回多项式的值y。
12. 分别制定N=1，4，10，通过上述函数进行训练
13. 什么时候使用lamda函数
14. 调用不同包中的函数，类似在不同层级的文件夹中找文件，该包中必须有该文件才能被打开。